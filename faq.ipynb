{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers textstat spacy -q\n",
    "!python -m spacy download en_core_web_md --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>bank</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>\\nOn your computer\\n1. Log in to E-Banking\\n\\n...</td>\n",
       "      <td>UBS</td>\n",
       "      <td>https://www.ubs.com/ch/en/help/creditcard/orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>Applying for a DBS Debit Card or Credit Card\\n...</td>\n",
       "      <td>DBS</td>\n",
       "      <td>https://www.dbs.com.sg/personal/cards/cards-fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>For new customers, you may submit your applica...</td>\n",
       "      <td>UOB</td>\n",
       "      <td>https://www.uob.com.sg/personal/customer-servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>The capital of France is Paris. Paris is the c...</td>\n",
       "      <td>bad_bank</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0  How do I apply for a Credit Card?   \n",
       "1  How do I apply for a Credit Card?   \n",
       "2  How do I apply for a Credit Card?   \n",
       "3  How do I apply for a Credit Card?   \n",
       "\n",
       "                                              answer      bank  \\\n",
       "0  \\nOn your computer\\n1. Log in to E-Banking\\n\\n...       UBS   \n",
       "1  Applying for a DBS Debit Card or Credit Card\\n...       DBS   \n",
       "2  For new customers, you may submit your applica...       UOB   \n",
       "3  The capital of France is Paris. Paris is the c...  bad_bank   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.ubs.com/ch/en/help/creditcard/orde...  \n",
       "1  https://www.dbs.com.sg/personal/cards/cards-fa...  \n",
       "2  https://www.uob.com.sg/personal/customer-servi...  \n",
       "3                                               None  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to order credit card online \n",
    "\n",
    "ubs = [\"\"\"How do I apply for a Credit Card?\"\"\",\n",
    "\"\"\"\n",
    "On your computer\n",
    "1. Log in to E-Banking\n",
    "\n",
    "2. Navigate to Products and click the option Cards\n",
    "\n",
    "<< Annotated Image of E-Banking Screenshot: Menu - cards. Shows where to click. >>\n",
    "3. Choose the card that fulfills your needs and click Apply for it\n",
    "\n",
    "<< Annotated Image of  of E-Banking Screenshot: Apply for card >>\n",
    "\n",
    "Your card will be sent to you by mail.\"\"\", 'UBS', \n",
    "'https://www.ubs.com/ch/en/help/creditcard/order.html?campID=ubs_Smart_Search']\n",
    "\n",
    "\n",
    "uob = [\"\"\"How do I apply for a Credit Card?\"\"\",\n",
    "\"\"\"For new customers, you may submit your application online through our website at http://www.uob.com.sg/cards.\n",
    "\n",
    "For existing customers, please log in to your UOB Personal Internet Banking / UOB TMRW to apply for a new card.\"\"\",\n",
    "'UOB', 'https://www.uob.com.sg/personal/customer-service/credit-card.page'\n",
    "\n",
    "]\n",
    "\n",
    "dbs = [\"\"\"How do I apply for a Credit Card?\"\"\", \n",
    "\"\"\"Applying for a DBS Debit Card or Credit Card\n",
    "Am I eligible for a debit card?\n",
    "\n",
    "You must be at least 16 years old and have a POSB Savings Account, DBS Savings Plus Account, DBS Autosave Account or DBS Current Account. To open one of these accounts, click here.\n",
    "\n",
    "If you are a foreigner, please apply for a debit card at any of our branches. You will need to present your passport and an employment pass that is valid for at least 6 months.\n",
    "\n",
    "\n",
    "Am I eligible for a credit card?\n",
    "\n",
    "If you're Singaporean or have permanent residency and you're over 21 years of age, you can apply for a DBS Credit Card. You'll need to earn at least S$30,000 a year. If you're a foreigner with a valid employment pass, you'll need to earn at least S$45,000 a year unless otherwise stated. For DBS Vantage Card, you'll need to earn S$120,000 annually.\n",
    "\n",
    "\n",
    "What do I need to apply?\n",
    "\n",
    "The type of document youâ€™ll need varies. Click here for detailed list.\n",
    "\"\"\",\n",
    "\"DBS\", 'https://www.dbs.com.sg/personal/cards/cards-faqs.page']\n",
    "\n",
    "bad_bank =  [\"How do I apply for a Credit Card?\",\n",
    "             \"The capital of France is Paris. Paris is the capital of France. Paris is known for its art and culture.\",\n",
    "             \"bad_bank\",\n",
    "             None\n",
    "             ]\n",
    "\n",
    "\n",
    "COLS = ['question', 'answer', 'bank', 'url']\n",
    "# Create individual DataFrames and combine them\n",
    "df = pd.concat([pd.DataFrame(data, index=COLS).T for data in (ubs, dbs, uob, bad_bank)], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A Evaluative Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Score: 0.8146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "# Load a better pre-trained sentence transformer model\n",
    "MODEL_NAME = \"multi-qa-mpnet-base-dot-v1\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "def compute_relevance(query: str, faq_text: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the relevance score between a query and FAQ text using cosine similarity.\n",
    "    \"\"\"\n",
    "    # Encode the query and FAQ text into embeddings\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    faq_embedding = model.encode(faq_text, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity between the embeddings\n",
    "    relevance_score = util.cos_sim(query_embedding, faq_embedding).item()\n",
    "    return relevance_score\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"How to apply for a credit card?\"\n",
    "    faq_text = \"You can apply for a credit card online by visiting our website and filling out the application form.\"\n",
    "\n",
    "    relevance_score = compute_relevance(query, faq_text)\n",
    "    print(f\"Relevance Score: {relevance_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import textstat\n",
    "\n",
    "# Function to compute clarity score using Flesch-Kincaid readability\n",
    "def compute_clarity(text):\n",
    "    clarity_score = textstat.flesch_reading_ease(text)\n",
    "    clarity_score = clarity_score / 100  # Normalize to 0-1 scale\n",
    "    return clarity_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conciseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load NLP models\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Lightweight but powerful\n",
    "\n",
    "def calculate_redundancy(text):\n",
    "    \"\"\"\n",
    "    Calculate redundancy using SBERT embeddings and cosine similarity.\n",
    "    Returns a score between 0 and 1 (1 = highly redundant).\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "    if len(sentences) < 2:\n",
    "        return 0.0  # No redundancy if only one sentence\n",
    "\n",
    "    # Convert sentences into SBERT embeddings\n",
    "    embeddings = sbert_model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(embeddings.cpu().numpy())\n",
    "\n",
    "    # Compute average similarity between different sentences\n",
    "    redundancy_score = np.mean([\n",
    "        similarity_matrix[i, j]\n",
    "        for i in range(len(sentences)) for j in range(len(sentences)) if i != j\n",
    "    ])\n",
    "\n",
    "    return redundancy_score\n",
    "\n",
    "def calculate_semantic_density(text):\n",
    "    \"\"\"\n",
    "    Calculate semantic density: proportion of meaningful words.\n",
    "    Weighted scoring gives more importance to Nouns & Verbs.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    meaningful_words = [token for token in doc if token.pos_ in [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"] and not token.is_stop]\n",
    "    \n",
    "    # Assign higher weights to key content words\n",
    "    weights = {\"NOUN\": 1.2, \"VERB\": 1.5, \"ADJ\": 1.0, \"ADV\": 0.8}\n",
    "    weighted_count = sum(weights[token.pos_] for token in meaningful_words)\n",
    "\n",
    "    semantic_density = weighted_count / len(doc) if len(doc) > 0 else 0.0\n",
    "    return semantic_density\n",
    "\n",
    "def calculate_conciseness_score(text, weights: tuple = (0.3, 0.5, 0.2)) -> float:\n",
    "    \"\"\"\n",
    "    Combine redundancy, semantic density, and length penalty into a conciseness metric.\n",
    "    \"\"\"\n",
    "    # Normalize redundancy (lower is better, so we invert it)\n",
    "    normalized_redundancy = 1 - calculate_redundancy(text)\n",
    "\n",
    "    # Add a length penalty (longer text reduces conciseness)\n",
    "    length_penalty = max(0, 1 - (len(text.split()) / 100))  # Penalizes texts >100 words\n",
    "\n",
    "    # Weighted combination\n",
    "    w_r, w_s, w_l = weights\n",
    "    conciseness_score = (\n",
    "        w_r * normalized_redundancy + \n",
    "        w_s * calculate_semantic_density(text) +\n",
    "        w_l * length_penalty\n",
    "    )\n",
    "\n",
    "    return conciseness_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def calculate_redundancy(text):\n",
    "    \"\"\"Compute redundancy using SBERT embeddings and cosine similarity.\"\"\"\n",
    "    sentences = [sent.text.strip() for sent in nlp(text).sents if sent.text.strip()]\n",
    "    if len(sentences) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    # Load SBERT model only when needed\n",
    "    sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings = sbert.encode(sentences, convert_to_tensor=True).cpu().numpy()\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    return np.mean([similarity_matrix[i, j] for i in range(len(sentences)) for j in range(len(sentences)) if i != j])\n",
    "\n",
    "def calculate_semantic_density(text):\n",
    "    \"\"\"Compute proportion of meaningful words, giving higher weight to key parts of speech.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    weights = {\"NOUN\": 1.2, \"VERB\": 1.5, \"ADJ\": 1.0, \"ADV\": 0.8}\n",
    "    \n",
    "    weighted_count = sum(weights.get(token.pos_, 0) for token in doc if not token.is_stop)\n",
    "    return weighted_count / len(doc) if doc else 0.0\n",
    "\n",
    "def calculate_conciseness_score(text, weights=(0.3, 0.5, 0.2)):\n",
    "    \"\"\"Combine redundancy, semantic density, and length penalty into a conciseness score.\"\"\"\n",
    "    w_r, w_s, w_l = weights\n",
    "    length_penalty = max(0, 1 - (len(text.split()) / 100))  # Penalizes overly long text\n",
    "    \n",
    "    return w_r * (1 - calculate_redundancy(text)) + w_s * calculate_semantic_density(text) + w_l * length_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>bank</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>clarity_score</th>\n",
       "      <th>conciseness_score</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>\\nOn your computer\\n1. Log in to E-Banking\\n\\n...</td>\n",
       "      <td>UBS</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>Applying for a DBS Debit Card or Credit Card\\n...</td>\n",
       "      <td>DBS</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>For new customers, you may submit your applica...</td>\n",
       "      <td>UOB</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I apply for a Credit Card?</td>\n",
       "      <td>The capital of France is Paris. Paris is the c...</td>\n",
       "      <td>bad_bank</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0  How do I apply for a Credit Card?   \n",
       "1  How do I apply for a Credit Card?   \n",
       "2  How do I apply for a Credit Card?   \n",
       "3  How do I apply for a Credit Card?   \n",
       "\n",
       "                                              answer      bank  \\\n",
       "0  \\nOn your computer\\n1. Log in to E-Banking\\n\\n...       UBS   \n",
       "1  Applying for a DBS Debit Card or Credit Card\\n...       DBS   \n",
       "2  For new customers, you may submit your applica...       UOB   \n",
       "3  The capital of France is Paris. Paris is the c...  bad_bank   \n",
       "\n",
       "   relevance_score  clarity_score  conciseness_score  combined_score  \n",
       "0             0.79           0.76               0.47            0.75  \n",
       "1             0.57           0.75               0.38            0.61  \n",
       "2             0.69           0.46               0.42            0.59  \n",
       "3             0.43           0.82               0.36            0.54  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to compute combined score\n",
    "def compute_combined_score(relevance, clarity, conciseness, weights):\n",
    "    combined_score = (\n",
    "        weights[\"relevance\"] * relevance +\n",
    "        weights[\"clarity\"] * clarity +\n",
    "        weights[\"conciseness\"] * conciseness\n",
    "    )\n",
    "    return combined_score\n",
    "\n",
    "# Define weights for each criterion\n",
    "weights = {\"relevance\": 0.6, \"clarity\": 0.3, \"conciseness\": 0.1}\n",
    "\n",
    "# User query\n",
    "user_query = \"How do I apply for a Credit Card?\"\n",
    "\n",
    "# Evaluate each Q&A pair in the DataFrame\n",
    "df[\"relevance_score\"] = df.apply(lambda row: compute_relevance(user_query, f\"{row['question']} {row['answer']}\"), axis=1)\n",
    "df[\"clarity_score\"] = df[\"answer\"].apply(compute_clarity)\n",
    "df[\"conciseness_score\"] = df[\"answer\"].apply(calculate_conciseness_score)\n",
    "df[\"combined_score\"] = df.apply(\n",
    "    lambda row: compute_combined_score(\n",
    "        row[\"relevance_score\"], row[\"clarity_score\"], row[\"conciseness_score\"], weights\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Rank Q&A pairs by combined score\n",
    "df = df.sort_values(by=\"combined_score\", ascending=False).reset_index(drop=True)\n",
    "score_cols = df.filter(regex='score').columns\n",
    "df[score_cols] = df[score_cols].round(2)\n",
    "df.drop(columns='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
